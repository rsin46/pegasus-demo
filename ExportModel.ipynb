{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Pegasus Model to pb Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Place this file inside pegasus [folder](https://github.com/google-research/pegasus) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import time\n",
    "\n",
    "from absl import logging\n",
    "from pegasus.data import infeed\n",
    "from pegasus.params import all_params  # pylint: disable=unused-import\n",
    "from pegasus.params import estimator_utils\n",
    "from pegasus.params import registry\n",
    "import tensorflow as tf\n",
    "from pegasus.eval import text_eval\n",
    "from pegasus.ops import public_parsing_ops\n",
    "import pandas as pd\n",
    "from random import choice\n",
    "from tensorflow.python.estimator.export import export\n",
    "tf.enable_eager_execution()\n",
    "# import tensorflow_transform as tft\n",
    "data_name = 'newsroom'\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "master = \"\"\n",
    "model_dir = \"./ckpt/pegasus_ckpt/%s\"%data_name\n",
    "use_tpu = False\n",
    "iterations_per_loop = 1000\n",
    "num_shards = 1\n",
    "param_overrides = \"vocab_filename=ckpt/pegasus_ckpt/c4.unigram.newline.10pct.96000.model,batch_size=1,beam_size=5,beam_alpha=0.6\"\n",
    "\n",
    "eval_dir = os.path.dirname(model_dir)\n",
    "checkpoint_path = model_dir\n",
    "checkpoint_path = tf.train.latest_checkpoint(checkpoint_path )\n",
    "params = registry.get_params('%s_transformer'%data_name)(param_overrides)\n",
    "pattern = params.dev_pattern\n",
    "input_fn = infeed.get_input_fn(params.parser, pattern,\n",
    "                                     tf.estimator.ModeKeys.PREDICT)\n",
    "parser, shapes = params.parser(mode=tf.estimator.ModeKeys.PREDICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FEATURE_SPEC = dict([(\"inputs\", tf.io.FixedLenFeature(shapes['inputs'], tf.int64)), \n",
    "                               ('targets', tf.io.FixedLenFeature(shapes['targets'], tf.string))])\n",
    "\n",
    "raw_feature_spec = RAW_DATA_FEATURE_SPEC.copy()\n",
    "raw_feature_spec.pop('targets')\n",
    "# raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "#         raw_feature_spec, default_batch_size=0)\n",
    "def serving_input_fn():\n",
    "    raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "        raw_feature_spec, default_batch_size=1)\n",
    "    serving_input_receiver = raw_input_fn()\n",
    "\n",
    "    raw_features = serving_input_receiver.features\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        raw_features, serving_input_receiver.receiver_tensors)\n",
    "\n",
    "print(tf.executing_eagerly())\n",
    "estimator = estimator_utils.create_estimator(master, \n",
    "                                             model_dir,\n",
    "                                             use_tpu,\n",
    "                                             iterations_per_loop,\n",
    "                                             num_shards, params, include_features_in_predictions=False)\n",
    "\n",
    "estimator.export_saved_model(\n",
    "    \"model/\", serving_input_fn\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
